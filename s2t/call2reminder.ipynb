{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import speech_recognition as sr\n",
    "  import pyttsx3\n",
    "  import pyaudio\n",
    "  import sumy\n",
    "except:\n",
    "  !pip install  speechrecognition\n",
    "  !pip install  pyttsx3\n",
    "  !pip install  pyaudio\n",
    "  !pip install spacy\n",
    "  !pip install sumy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.8.1.78-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "     ---------------------------------------- 0.0/38.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.2/38.1 MB 5.1 MB/s eta 0:00:08\n",
      "      --------------------------------------- 0.5/38.1 MB 6.3 MB/s eta 0:00:06\n",
      "     - -------------------------------------- 1.0/38.1 MB 7.6 MB/s eta 0:00:05\n",
      "     - -------------------------------------- 1.5/38.1 MB 8.9 MB/s eta 0:00:05\n",
      "     -- ------------------------------------- 2.2/38.1 MB 10.1 MB/s eta 0:00:04\n",
      "     --- ------------------------------------ 3.1/38.1 MB 10.9 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 4.3/38.1 MB 13.6 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 6.1/38.1 MB 16.2 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 7.7/38.1 MB 18.2 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 9.3/38.1 MB 19.9 MB/s eta 0:00:02\n",
      "     ------------ -------------------------- 11.8/38.1 MB 31.2 MB/s eta 0:00:01\n",
      "     --------------- ----------------------- 14.7/38.1 MB 46.7 MB/s eta 0:00:01\n",
      "     ------------------ -------------------- 18.1/38.1 MB 65.6 MB/s eta 0:00:01\n",
      "     ---------------------- ---------------- 21.6/38.1 MB 65.2 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 23.8/38.1 MB 54.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 25.5/38.1 MB 54.7 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 26.2/38.1 MB 46.7 MB/s eta 0:00:01\n",
      "     --------------------------- ----------- 26.9/38.1 MB 36.3 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 27.4/38.1 MB 31.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 28.1/38.1 MB 28.5 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 28.6/38.1 MB 26.2 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 28.9/38.1 MB 23.4 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 29.4/38.1 MB 22.6 MB/s eta 0:00:01\n",
      "     ------------------------------ -------- 29.8/38.1 MB 21.1 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 30.4/38.1 MB 18.7 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 30.9/38.1 MB 17.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 31.3/38.1 MB 16.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 31.8/38.1 MB 15.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 32.3/38.1 MB 14.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ----- 32.8/38.1 MB 14.5 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 33.4/38.1 MB 13.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 34.1/38.1 MB 13.1 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 34.7/38.1 MB 12.1 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 35.4/38.1 MB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ -- 35.9/38.1 MB 11.3 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 36.4/38.1 MB 10.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 36.8/38.1 MB 11.5 MB/s eta 0:00:01\n",
      "     --------------------------------------  37.4/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  37.8/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     --------------------------------------  38.1/38.1 MB 11.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 38.1/38.1 MB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\anshul\\miniconda3\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.8.1.78\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"16-122828-0002.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I believe you are just talking nonsense\n"
     ]
    }
   ],
   "source": [
    "with sr.AudioFile(filename) as source:\n",
    "    # listen for the data (load audio to memory)\n",
    "    audio_data = r.record(source)\n",
    "    # recognize (convert from speech to text)\n",
    "    text = r.recognize_google(audio_data)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anshul\\miniconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "# create a speech recognition object\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# a function to recognize speech in the audio file\n",
    "# so that we don't repeat ourselves in in other functions\n",
    "def transcribe_audio(path):\n",
    "    # use the audio file as the audio source\n",
    "    with sr.AudioFile(path) as source:\n",
    "        audio_listened = r.record(source)\n",
    "        # try converting it to text\n",
    "        text = r.recognize_google(audio_listened)\n",
    "    return text\n",
    "\n",
    "# a function that splits the audio file into chunks on silence\n",
    "# and applies speech recognition\n",
    "def get_large_audio_transcription_on_silence(path):\n",
    "    \"\"\"Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_file(path)  \n",
    "    # split audio sound where silence is 500 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 500,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-14,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        try:\n",
    "            text = transcribe_audio(chunk_filename)\n",
    "        except sr.UnknownValueError as e:\n",
    "            print(\"Error:\", str(e))\n",
    "        else:\n",
    "            text = f\"{text.capitalize()}. \"\n",
    "            print(chunk_filename, \":\", text)\n",
    "            whole_text += text\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-chunks\\chunk1.wav : He is about which she had fixed in a bowl for countryside. \n",
      "audio-chunks\\chunk2.wav : Resort distance from the city. \n",
      "audio-chunks\\chunk3.wav : Just that what is now called dutch street. \n",
      "audio-chunks\\chunk4.wav : Sonu bounded with proof of his engine novelty. \n",
      "audio-chunks\\chunk5.wav : Find smoke. \n",
      "audio-chunks\\chunk6.wav : Set required horse to work some. \n",
      "audio-chunks\\chunk7.wav : Torch on the roasted meat without fire. \n",
      "audio-chunks\\chunk8.wav : Cards the one before the horses. \n",
      "audio-chunks\\chunk9.wav : Weather cock so turned against the wind and other wrong headed could drivers. \n",
      "audio-chunks\\chunk10.wav : Restaurants in confounded all beholders. \n",
      "\n",
      "Full text: He is about which she had fixed in a bowl for countryside. Resort distance from the city. Just that what is now called dutch street. Sonu bounded with proof of his engine novelty. Find smoke. Set required horse to work some. Torch on the roasted meat without fire. Cards the one before the horses. Weather cock so turned against the wind and other wrong headed could drivers. Restaurants in confounded all beholders. \n"
     ]
    }
   ],
   "source": [
    "path = \"7601-291468-0006.wav\"\n",
    "print(\"\\nFull text:\", get_large_audio_transcription_on_silence(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-chunks\\chunk1.wav : He is about which she had fixed at a bowl or countryside. \n",
      "audio-chunks\\chunk2.wav : Resort distance from the city. \n",
      "audio-chunks\\chunk3.wav : Just that what is now called dutch street. \n",
      "audio-chunks\\chunk4.wav : Sonu bounded with proof of his engine novelty. \n",
      "audio-chunks\\chunk5.wav : Find smoke. \n",
      "audio-chunks\\chunk6.wav : Set required horse to work some. \n",
      "audio-chunks\\chunk7.wav : Torch open the roasted meat without fire. \n",
      "audio-chunks\\chunk8.wav : Cards the one before the horses. \n",
      "audio-chunks\\chunk9.wav : Weather cock so turned against the wind and other wrong headed could drivers. \n",
      "audio-chunks\\chunk10.wav : Restaurants in confounded all beholders. \n"
     ]
    }
   ],
   "source": [
    "a=get_large_audio_transcription_on_silence(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He is about which she had fixed at a bowl or countryside. Resort distance from the city. Just that what is now called dutch street. Sonu bounded with proof of his engine novelty. Find smoke. Set required horse to work some. Torch open the roasted meat without fire. Cards the one before the horses. Weather cock so turned against the wind and other wrong headed could drivers. Restaurants in confounded all beholders. '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a='when you come back from office please buy grocerries . 4 eggs,10 apples '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when you come back from office please buy grocerries .4 eggs,10 apples\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "\n",
    "# Creating text parser using tokenization\n",
    "parser = PlaintextParser.from_string(a, Tokenizer(\"english\"))\n",
    "\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "\n",
    "# Summarize using sumy TextRank\n",
    "summarizer = TextRankSummarizer()\n",
    "summary = summarizer(parser.document, 2)\n",
    "\n",
    "text_summary = \"\"\n",
    "for sentence in summary:\n",
    "  text_summary += str(sentence)\n",
    "\n",
    "print(text_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_sci_lg'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32me:\\Users\\anshul\\Desktop\\ml_prac\\s2t\\call2reminder.ipynb Cell 12\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Users/anshul/Desktop/ml_prac/s2t/call2reminder.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Users/anshul/Desktop/ml_prac/s2t/call2reminder.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39men_core_sci_lg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Users/anshul/Desktop/ml_prac/s2t/call2reminder.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39mspaCy is an open-source software library for advanced natural language processing, \u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Users/anshul/Desktop/ml_prac/s2t/call2reminder.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwritten in the programming languages Python and Cython. The library is published under the MIT license\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Users/anshul/Desktop/ml_prac/s2t/call2reminder.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mand its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Users/anshul/Desktop/ml_prac/s2t/call2reminder.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m doc \u001b[39m=\u001b[39m nlp(text)\n",
      "File \u001b[1;32mc:\\Users\\anshul\\miniconda3\\lib\\site-packages\\spacy\\__init__.py:54\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m     31\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m     32\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     37\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     38\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[0;32m     39\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m     55\u001b[0m         name,\n\u001b[0;32m     56\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m     57\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m     58\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m     59\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m     60\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m     61\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\anshul\\miniconda3\\lib\\site-packages\\spacy\\util.py:439\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    438\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 439\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_sci_lg'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "text = \"\"\"spaCy is an open-source software library for advanced natural language processing, \n",
    "written in the programming languages Python and Cython. The library is published under the MIT license\n",
    "and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\"\n",
    "doc = nlp(text)\n",
    "print(doc.ents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'base (Python 3.10.10)' due to a timeout waiting for the ports to get used. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
