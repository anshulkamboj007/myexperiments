{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import speech_recognition as sr\n",
    "  import pyttsx3\n",
    "  import pyaudio\n",
    "  import sumy\n",
    "except:\n",
    "  !pip install  speechrecognition\n",
    "  !pip install  pyttsx3\n",
    "  !pip install  pyaudio\n",
    "  !pip install spacy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sumy\n",
      "  Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
      "     ---------------------------------------- 0.0/97.3 kB ? eta -:--:--\n",
      "     ------------------------------------- -- 92.2/97.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 97.3/97.3 kB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: nltk>=3.0.2 in c:\\users\\anshul\\miniconda3\\lib\\site-packages (from sumy) (3.8.1)\n",
      "Collecting docopt<0.7,>=0.6.1\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting breadability>=0.1.20\n",
      "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pycountry>=18.2.23\n",
      "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
      "     ---------------------------------------- 0.0/10.1 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 1.6/10.1 MB 33.1 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 3.5/10.1 MB 32.3 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 5.7/10.1 MB 36.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 9.8/10.1 MB 44.7 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.1/10.1 MB 46.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.1/10.1 MB 46.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.1/10.1 MB 46.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.1/10.1 MB 46.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.1/10.1 MB 46.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.1/10.1 MB 46.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.1/10.1 MB 46.2 MB/s eta 0:00:01\n",
      "     --------------------------------------  10.1/10.1 MB 46.2 MB/s eta 0:00:01\n",
      "     --------------------------------------- 10.1/10.1 MB 16.6 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\anshul\\miniconda3\\lib\\site-packages (from sumy) (2.28.1)\n",
      "Collecting chardet\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "     ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "     ------------------------------------  194.6/199.4 kB 11.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  194.6/199.4 kB 11.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- 199.4/199.4 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting lxml>=2.0\n",
      "  Downloading lxml-4.9.3-cp310-cp310-win_amd64.whl (3.8 MB)\n",
      "     ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "     ---------------------------------- ----- 3.2/3.8 MB 68.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.8/3.8 MB 80.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.8/3.8 MB 34.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click in c:\\users\\anshul\\miniconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (8.1.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anshul\\miniconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (4.65.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\anshul\\appdata\\roaming\\python\\python310\\site-packages (from nltk>=3.0.2->sumy) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\anshul\\miniconda3\\lib\\site-packages (from nltk>=3.0.2->sumy) (2023.8.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anshul\\miniconda3\\lib\\site-packages (from pycountry>=18.2.23->sumy) (65.6.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\anshul\\miniconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anshul\\miniconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\anshul\\miniconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anshul\\miniconda3\\lib\\site-packages (from requests>=2.7.0->sumy) (2022.12.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\anshul\\miniconda3\\lib\\site-packages (from click->nltk>=3.0.2->sumy) (0.4.6)\n",
      "Building wheels for collected packages: breadability, docopt, pycountry\n",
      "  Building wheel for breadability (setup.py): started\n",
      "  Building wheel for breadability (setup.py): finished with status 'done'\n",
      "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21743 sha256=156f9aa46179b7bfb7ca0a26f386b0d5fed15b94eb6281b2c64861ebc6b60ac3\n",
      "  Stored in directory: c:\\users\\anshul\\appdata\\local\\pip\\cache\\wheels\\64\\22\\90\\b84fcc30e16598db20a0d41340616dbf9b1e82bbcc627b0b33\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13775 sha256=a35d42b192d6da327428124b10f4b95da3089401d24d1dc911e2eef67ae2d374\n",
      "  Stored in directory: c:\\users\\anshul\\appdata\\local\\pip\\cache\\wheels\\fc\\ab\\d4\\5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "  Building wheel for pycountry (pyproject.toml): started\n",
      "  Building wheel for pycountry (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681895 sha256=413cccb57400272ce312785333a432f9dd1f6b0c43dc0a385d8a8438d5c5add8\n",
      "  Stored in directory: c:\\users\\anshul\\appdata\\local\\pip\\cache\\wheels\\03\\57\\cc\\290c5252ec97a6d78d36479a3c5e5ecc76318afcb241ad9dbe\n",
      "Successfully built breadability docopt pycountry\n",
      "Installing collected packages: docopt, pycountry, lxml, chardet, breadability, sumy\n",
      "Successfully installed breadability-0.1.20 chardet-5.2.0 docopt-0.6.2 lxml-4.9.3 pycountry-22.3.5 sumy-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"16-122828-0002.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I believe you are just talking nonsense\n"
     ]
    }
   ],
   "source": [
    "with sr.AudioFile(filename) as source:\n",
    "    # listen for the data (load audio to memory)\n",
    "    audio_data = r.record(source)\n",
    "    # recognize (convert from speech to text)\n",
    "    text = r.recognize_google(audio_data)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anshul\\miniconda3\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr \n",
    "import os \n",
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "# create a speech recognition object\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# a function to recognize speech in the audio file\n",
    "# so that we don't repeat ourselves in in other functions\n",
    "def transcribe_audio(path):\n",
    "    # use the audio file as the audio source\n",
    "    with sr.AudioFile(path) as source:\n",
    "        audio_listened = r.record(source)\n",
    "        # try converting it to text\n",
    "        text = r.recognize_google(audio_listened)\n",
    "    return text\n",
    "\n",
    "# a function that splits the audio file into chunks on silence\n",
    "# and applies speech recognition\n",
    "def get_large_audio_transcription_on_silence(path):\n",
    "    \"\"\"Splitting the large audio file into chunks\n",
    "    and apply speech recognition on each of these chunks\"\"\"\n",
    "    # open the audio file using pydub\n",
    "    sound = AudioSegment.from_file(path)  \n",
    "    # split audio sound where silence is 500 miliseconds or more and get chunks\n",
    "    chunks = split_on_silence(sound,\n",
    "        # experiment with this value for your target audio file\n",
    "        min_silence_len = 500,\n",
    "        # adjust this per requirement\n",
    "        silence_thresh = sound.dBFS-14,\n",
    "        # keep the silence for 1 second, adjustable as well\n",
    "        keep_silence=500,\n",
    "    )\n",
    "    folder_name = \"audio-chunks\"\n",
    "    # create a directory to store the audio chunks\n",
    "    if not os.path.isdir(folder_name):\n",
    "        os.mkdir(folder_name)\n",
    "    whole_text = \"\"\n",
    "    # process each chunk \n",
    "    for i, audio_chunk in enumerate(chunks, start=1):\n",
    "        # export audio chunk and save it in\n",
    "        # the `folder_name` directory.\n",
    "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
    "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
    "        # recognize the chunk\n",
    "        try:\n",
    "            text = transcribe_audio(chunk_filename)\n",
    "        except sr.UnknownValueError as e:\n",
    "            print(\"Error:\", str(e))\n",
    "        else:\n",
    "            text = f\"{text.capitalize()}. \"\n",
    "            print(chunk_filename, \":\", text)\n",
    "            whole_text += text\n",
    "    # return the text for all chunks detected\n",
    "    return whole_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-chunks\\chunk1.wav : He is about which she had fixed at a bowl or countryside. \n",
      "audio-chunks\\chunk2.wav : Resort distance from the city. \n",
      "audio-chunks\\chunk3.wav : Just that what is now called dutch street. \n",
      "audio-chunks\\chunk4.wav : Sonu bounded with proof of his engine novelty. \n",
      "audio-chunks\\chunk5.wav : Find smoke. \n",
      "audio-chunks\\chunk6.wav : Set required horse to work some. \n",
      "audio-chunks\\chunk7.wav : Torch on the roasted meat without fire. \n",
      "audio-chunks\\chunk8.wav : Cards the one before the horses. \n",
      "audio-chunks\\chunk9.wav : Weather cock so turned against the wind and other wrong headed could drivers. \n",
      "audio-chunks\\chunk10.wav : Restaurants in confounded all beholders. \n",
      "\n",
      "Full text: He is about which she had fixed at a bowl or countryside. Resort distance from the city. Just that what is now called dutch street. Sonu bounded with proof of his engine novelty. Find smoke. Set required horse to work some. Torch on the roasted meat without fire. Cards the one before the horses. Weather cock so turned against the wind and other wrong headed could drivers. Restaurants in confounded all beholders. \n"
     ]
    }
   ],
   "source": [
    "path = \"7601-291468-0006.wav\"\n",
    "print(\"\\nFull text:\", get_large_audio_transcription_on_silence(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio-chunks\\chunk1.wav : He is about which she had fixed in a bowl for countryside. \n",
      "audio-chunks\\chunk2.wav : Resort distance from the city. \n",
      "audio-chunks\\chunk3.wav : Just that what is now called dutch street. \n",
      "audio-chunks\\chunk4.wav : Sonu bounded with proof of his engine novelty. \n",
      "audio-chunks\\chunk5.wav : Find smoke. \n",
      "audio-chunks\\chunk6.wav : Set required horse to work some. \n",
      "audio-chunks\\chunk7.wav : Torch open the roasted meat without fire. \n",
      "audio-chunks\\chunk8.wav : Cards the one before the horses. \n",
      "audio-chunks\\chunk9.wav : Weather cock so turned against the wind and other wrong headed could drivers. \n",
      "audio-chunks\\chunk10.wav : Restaurants in confounded all beholders. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'He is about which she had fixed in a bowl for countryside. Resort distance from the city. Just that what is now called dutch street. Sonu bounded with proof of his engine novelty. Find smoke. Set required horse to work some. Torch open the roasted meat without fire. Cards the one before the horses. Weather cock so turned against the wind and other wrong headed could drivers. Restaurants in confounded all beholders. '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=get_large_audio_transcription_on_silence(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He is about which she had fixed in a bowl for countryside. Resort distance from the city. Just that what is now called dutch street. Sonu bounded with proof of his engine novelty. Find smoke. Set required horse to work some. Torch open the roasted meat without fire. Cards the one before the horses. Weather cock so turned against the wind and other wrong headed could drivers. Restaurants in confounded all beholders. '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "a='when you come back from office please buy grocerries . 4 eggs,10 apples '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when you come back from office please buy grocerries .4 eggs,10 apples\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "\n",
    "# Creating text parser using tokenization\n",
    "parser = PlaintextParser.from_string(a, Tokenizer(\"english\"))\n",
    "\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer\n",
    "\n",
    "# Summarize using sumy TextRank\n",
    "summarizer = TextRankSummarizer()\n",
    "summary = summarizer(parser.document, 2)\n",
    "\n",
    "text_summary = \"\"\n",
    "for sentence in summary:\n",
    "  text_summary += str(sentence)\n",
    "\n",
    "print(text_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_sci_lg'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32me:\\Users\\anshul\\Desktop\\ml_prac\\s2t\\call2reminder.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Users/anshul/Desktop/ml_prac/s2t/call2reminder.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/Users/anshul/Desktop/ml_prac/s2t/call2reminder.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39men_core_sci_lg\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Users/anshul/Desktop/ml_prac/s2t/call2reminder.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39mspaCy is an open-source software library for advanced natural language processing, \u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Users/anshul/Desktop/ml_prac/s2t/call2reminder.ipynb#X21sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwritten in the programming languages Python and Cython. The library is published under the MIT license\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Users/anshul/Desktop/ml_prac/s2t/call2reminder.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mand its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/Users/anshul/Desktop/ml_prac/s2t/call2reminder.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m doc \u001b[39m=\u001b[39m nlp(text)\n",
      "File \u001b[1;32mc:\\Users\\anshul\\miniconda3\\lib\\site-packages\\spacy\\__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[0;32m     28\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[0;32m     29\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     35\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[0;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m     52\u001b[0m         name,\n\u001b[0;32m     53\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[0;32m     54\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[0;32m     55\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[0;32m     56\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[0;32m     57\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[0;32m     58\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\anshul\\miniconda3\\lib\\site-packages\\spacy\\util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    471\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 472\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_sci_lg'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_sci_lg\")\n",
    "text = \"\"\"spaCy is an open-source software library for advanced natural language processing, \n",
    "written in the programming languages Python and Cython. The library is published under the MIT license\n",
    "and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\"\n",
    "doc = nlp(text)\n",
    "print(doc.ents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
